<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Gilles Kratzer, Reinhard Furrer" />

<meta name="date" content="2020-03-01" />

<title>mcmcabn: A Structural Mcmc Sampler for Dags Learned from Observed Systemic Datasets</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">mcmcabn: A Structural Mcmc Sampler for Dags
Learned from Observed Systemic Datasets</h1>
<h4 class="author">Gilles Kratzer, Reinhard Furrer</h4>
<h4 class="date">2020-03-01</h4>



<p><strong>What is the package designed for?</strong></p>
<p>The three main problems addressed by this R package are:</p>
<ol style="list-style-type: decimal">
<li>Selecting the most probable structure based on a cache of
pre-computed scores.</li>
<li>Controlling for overfitting.</li>
<li>Sampling the landscape of high scoring structures.</li>
</ol>
<p>The latter could be beneficial in an applied perspective to avoid
reducing the richness of Bayesian network modeling to only
<strong>one</strong> structure. Indeed, it allows users to quantify the
marginal impact of relationships (arcs in a network) of interest by
marginalizing out over structures or nuisance dependencies (i.e., all
other possible relationships). Structural Monte Carlo Markov Chain
(MCMC) seems an elegant and natural way to estimate the <em>true</em>
marginal impact, so one can determine if it’s magnitude is big enough to
consider as a worthwhile intervention.</p>
<p>Note: in this vignette <em>structural</em> MCMC means that the MCMC
moves are performed at structure level (i.e., Bayesian network or
Directed Acyclic Graph (DAG)) and not at node ordering level for
example. The advantage is that explicit priors can be formulated. A DAG
is a graph used to encode the joint probability of a set of variables.
It is made of nodes (random variables) and arrows or arcs (directed
links representing the relationships among variables).</p>
<p><strong>How does it work?</strong></p>
<p>The <code>mcmcabn</code> R package takes a cache of pre-computed
network scores as input (possibly computed using
<code>buildScoreCache()</code> function from <code>abn</code> R
package). Then, the <code>mcmcabn()</code> function generates MCMC
samples from the posterior distribution of the most supported DAGs. To
do so the user should choose a structural prior and a learning scheme.
<code>mcmcabn</code> is equipped with multiple structural priors: the
so-called Koivisto prior (an uninformative prior), the Ellis prior (a
modular flat prior) and a possibly user define prior and three
algorithms for inferring the structure of Bayesian networks: the
classical Monte Carlo Markov Chain Model Choice ((MC)<span class="math inline">\(^3\)</span>), the new edge reversal (REV) from
Grzegorczyk and Husmeier (2008) and the Markov blanket resampling (MBR)
from Su and Borsuk (2016).</p>
<p><strong>What are the R package functionalities?</strong></p>
<p>The workhorse of the R package is the <code>mcmcabn()</code>
function. It generates MCMC samples from the posterior distribution of
the DAGs. This object of class <code>mcmcabn</code> can be summarized
with a comprehensive verbal description or a plot. From those samples,
one can either compute the most probable structure and plot the
cumulative maximum score achieved or analyze with the
<code>query()</code> R function that recognizes the formula statement.
For example, what is the probability of having an arc between two nodes,
one node being in the Markov blanket of another, or what is the
probability to <strong>not</strong> have an arc between two nodes?
Alternatively, one can query the frequency of an arc in one direction
relative to the opposite direction.</p>
<p><strong>Alternative R packages</strong></p>
<p><a href="https://CRAN.R-project.org/package=BiDAG">BiDAG</a> is an
MCMC sampler that combined partition MCMC with constrained based
methods. This R package is efficient to sample large DAGs.</p>
<p><strong>What is the structure of this document?</strong></p>
<p>We first illustrate the package with a simple example. Then some more
technical details are provided.</p>
<div id="simple-mcmcabn-example" class="section level1">
<h1>Simple <em>mcmcabn</em> example</h1>
<p>The package is available on <a href="https://CRAN.R-project.org/package=mcmcabn">CRAN</a> and can be
installed directly in R. However it needs two R packages: <a href="https://CRAN.R-project.org/package=abn">abn</a> and <a href="https://CRAN.R-project.org/package=gRbase">gRbase</a> that
requires libraries not stored on <a href="https://cran.r-project.org/">CRAN</a> but on <a href="http://www.bioconductor.org/">bioconductor</a>. Hence those two
packages <strong>must</strong> be installed <strong>before</strong>
installing <code>mcmcabn</code>:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;BiocManager&quot;</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>))</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">install.packages</span>(<span class="st">&quot;BiocManager&quot;</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>BiocManager<span class="sc">::</span><span class="fu">install</span>(<span class="fu">c</span>(<span class="st">&quot;RBGL&quot;</span>, <span class="st">&quot;Rgraphviz&quot;</span>, <span class="st">&quot;graph&quot;</span>),  <span class="at">version =</span> <span class="st">&quot;3.8&quot;</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;mcmcabn&quot;</span>)</span></code></pre></div>
<p>Once installed, the <code>mcmcabn</code> R package can be loaded
using:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mcmcabn)</span></code></pre></div>
<p>Let us start with an example from the <code>bnlearn</code> R package
from Scutari (2010). It is about a small synthetic dataset from
Lauritzen and Spiegelhalter (1988) about lung diseases (tuberculosis,
lung cancer, or bronchitis) and visits to Asia (8 nodes and 8 arcs). The
dataset is include in as <code>asia</code>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(abn) <span class="co"># to pre-compute the scores </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2) <span class="co"># plotting</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggpubr) <span class="co"># plotting</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cowplot) <span class="co"># plotting</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggdag) <span class="co"># to plot the DAG</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">#plot the BN as described in the paper</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>dag  <span class="ot">&lt;-</span> <span class="fu">dagify</span>(Tuberculosis<span class="sc">~</span>Asia,</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>               Either<span class="sc">~</span>Tuberculosis,</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>               XRay<span class="sc">~</span>Either,</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>               Dyspnea<span class="sc">~</span>Either,</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>               Bronchitis<span class="sc">~</span>Smoking,</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>               LungCancer<span class="sc">~</span>Smoking,</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>               Either<span class="sc">~</span>LungCancer,</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>               Dyspnea<span class="sc">~</span>Bronchitis)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="fu">ggdag_classic</span>(dag, <span class="at">size =</span> <span class="dv">6</span>) <span class="sc">+</span> <span class="fu">theme_dag_blank</span>()</span></code></pre></div>
<p><img src="data:image/png;base64,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" style="display: block; margin: auto;" /></p>
<p>One needs to pre-compute a cache of scores. We use the R package
<code>abn</code> to do it. For the first search, it is advised to limit
the number of parents per node to 2, which is the maximum number of
parents of the network.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#loglikelihood scores</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>abnCache<span class="fl">.2</span>par.asia <span class="ot">&lt;-</span> <span class="fu">buildScoreCache</span>(<span class="at">data.df =</span> asia,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">data.dists =</span> dist.asia,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">max.parents =</span> <span class="dv">2</span>)</span></code></pre></div>
<p>We use the <code>mcmcabn()</code> function on the cache of
pre-computed networks scores. One needs to define the type of score used
(here is the marginal likelihood <code>mlik</code> other choice are:
<code>bic</code>, <code>aic</code> or <code>mdl</code>). The maximum
number of parents per node (same as the one used in
<code>buildScoreCache()</code>). The MCMC learning scheme: number of
MCMC samples, number of thinned sampled (to avoid autocorrelation), and
the length of the burn-in phase. Here we choose: 1000 returned MCMC
steps and 99 thinned steps in between. It means that for each returned
MCMC move, 99 have been thinned. The burn-in phase is set to 10000
steps. We decide to initiate the algorithm with a random DAG
<code>start.dag = &quot;random&quot;</code>, which means that the function
randomly selects a valid DAG. In this context, valid means no cycle and
an appropriate maximum number of parents. The frequencies of selecting a
REV or the MBR jumps are set to 3%. It is usually a good idea to keep
those frequencies low. Indeed, REV and MBR are efficient in producing
high scoring structure but computationally costly compared to classical
MCMC jumps. We select the Koivisto prior
<code>prior.choice = 2</code>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>mcmc<span class="fl">.2</span>par.asia <span class="ot">&lt;-</span> <span class="fu">mcmcabn</span>(<span class="at">score.cache =</span> abnCache<span class="fl">.2</span>par.asia,</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>                         <span class="at">score =</span> <span class="st">&quot;mlik&quot;</span>,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">data.dists =</span> dist.asia,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>                         <span class="at">max.parents =</span> <span class="dv">2</span>,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>                         <span class="at">mcmc.scheme =</span> <span class="fu">c</span>(<span class="dv">1000</span>,<span class="dv">99</span>,<span class="dv">1000</span>),</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>                         <span class="at">seed =</span> <span class="dv">42</span>,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>                         <span class="at">verbose =</span> <span class="cn">FALSE</span>,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>                         <span class="at">start.dag =</span> <span class="st">&quot;random&quot;</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>                         <span class="at">prob.rev =</span> <span class="fl">0.03</span>,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>                         <span class="at">prob.mbr =</span> <span class="fl">0.03</span>, </span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>                         <span class="at">prior.choice =</span> <span class="dv">2</span>)</span></code></pre></div>
<p>The function <code>mcmcabn()</code> returns a list with multiple
entries:</p>
<ul>
<li><em>dags</em> is the list of sampled DAGs.</li>
<li><em>scores</em> is the list of DAGs scores.</li>
<li><em>alpha</em> is the acceptance probability of the
Metropolis-Hasting sampler.</li>
<li><em>method</em> is the algorithm chosen for the index MCMC
step.</li>
<li><em>rejection</em> if an MCMC jumps is rejected or not.</li>
<li><em>iterations</em> is the total number of MCMC iterations.</li>
<li><em>thinning</em> is the number of thinned steps for one returned
MCMC jump</li>
<li><em>burnin</em> is the length of the burn-in phase.</li>
<li><em>data.dist</em> is the list giving the distribution for each node
in the network.</li>
</ul>
<p>The object <code>mcmc.out</code> is of class <code>mcmcabn</code>. We
can check that we reach the maximum possible posterior DAG score even
with a small number of MCMC steps. To do so we use an exact search from
Koivisto 2004 implemented in <code>mostProbable()</code> from
<code>abn</code>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#maximum score get from the MCMC sampler</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(mcmc<span class="fl">.2</span>par.asia<span class="sc">$</span>scores)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] -11151</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">#maximum scoring network using exact search (not MCMC based) </span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>dag <span class="ot">&lt;-</span> <span class="fu">mostProbable</span>(<span class="at">score.cache =</span> abnCache<span class="fl">.2</span>par.asia)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Step1. completed max alpha_i(S) for all i and S</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Total sets g(S) to be evaluated over: 256</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="fu">fitAbn</span>(<span class="at">object =</span> dag,<span class="at">data.df =</span> asia, <span class="at">data.dists =</span> dist.asia)<span class="sc">$</span>mlik</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] -11151</span></span></code></pre></div>
<p>One can plot the output using the <em>plot()</em>. On the graph
below, one can see the trace plot of the posterior structure score. The
dashed red line is the maximum reached score (as expected = -11151). The
colored dots on the trace plot indicate when different methods have been
used. The densities on the left represent the relative occurring
frequencies of the methods.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mcmc<span class="fl">.2</span>par.asia)</span></code></pre></div>
<p><img src="data:image/png;base64,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" style="display: block; margin: auto;" /></p>
<p>One can also plot the cumulative best score over the MCMC steps. On
this graph, one can see the cumulated maximum posterior structure’s
score (as expected = -11151). The dashed red line is the maximum reached
score. The colored dots on the trace plot indicate when different
methods have been used.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mcmc<span class="fl">.2</span>par.asia, <span class="at">max.score =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" style="display: block; margin: auto;" /></p>
<p>One can also print the summary of the MCMC run:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mcmc<span class="fl">.2</span>par.asia)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; MCMC summary:</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Number of burn-in steps: 1000</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Number of MCMC steps: 1e+05</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Thinning: 99</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Maximum score: -11151</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Empirical mean: -11165</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Empirical standard deviation: 7.41</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Quantiles of the posterior network score:</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           0.025   0.25    0.5   0.75  0.975</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; BN score -11189 -11168 -11164 -11160 -11154</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Global acceptance rate: 0.205</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     Accepted Rejected</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; MBR        9       24</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; MC3      186      752</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; REV       10       20</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Sample size adjusted for autocorrelation: 51.6</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Autocorrelations by lag:</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     0     1     2     3     4     5     6     7     8    9    10</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; acf 1 0.568 0.562 0.523 0.478 0.459 0.457 0.419 0.402 0.37 0.335</span></span></code></pre></div>
<p>This function return some MCMC diagnostics and descriptive
metrics.</p>
<p>The main advantage of computing MCMC samples from the posterior is
that we can structurally query them. Hence we account for the
uncertainty in the structures through Bayesian model averaging. In
practice, we compute the probabilities of the arcs in the DAG or the
probability of a given part of a structure. Below are the individual
frequencies of the arcs.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">query</span>(<span class="at">mcmcabn =</span> mcmc<span class="fl">.2</span>par.asia)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                Asia Smoking Tuberculosis LungCancer Bronchitis Either   XRay</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Asia         0.0000  0.1698       0.1908      0.158      0.175 0.1229 0.1399</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Smoking      0.0829  0.0000       0.0799      0.440      0.424 0.0360 0.0230</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Tuberculosis 0.1319  0.1319       0.0000      0.277      0.123 0.1818 0.0390</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; LungCancer   0.0649  0.5125       0.2198      0.000      0.146 0.1499 0.0440</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Bronchitis   0.0809  0.5764       0.1389      0.149      0.000 0.0539 0.0360</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Either       0.0170  0.0529       0.8182      0.850      0.022 0.0000 0.0889</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; XRay         0.0649  0.0460       0.3047      0.271      0.032 0.7922 0.0000</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Dyspnea      0.0050  0.0000       0.0270      0.172      0.968 0.7552 0.0270</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;              Dyspnea</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Asia         0.13786</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Smoking      0.00000</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Tuberculosis 0.18681</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; LungCancer   0.03996</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Bronchitis   0.03197</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Either       0.00899</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; XRay         0.03596</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Dyspnea      0.00000</span></span></code></pre></div>
<p>The <code>query()</code> function takes formula statements. So it is
possible to explicitly query: <strong>what is the probability of
LungCancer node being children of the Smoking node?</strong></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">query</span>(<span class="at">mcmcabn =</span> mcmc<span class="fl">.2</span>par.asia, <span class="at">formula =</span> <span class="sc">~</span> LungCancer<span class="sc">|</span>Smoking)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.512</span></span></code></pre></div>
<p>This means that an arrow from Smoking to LungCancer appears in
51.249% of the sampled DAGs.</p>
<p>One can also ask more complicated structural requests. If we want to
know <strong>what is the probability of Smoking node being parent of
both LungCancer and Bronchitis node?</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">query</span>(<span class="at">mcmcabn =</span> mcmc<span class="fl">.2</span>par.asia, <span class="at">formula =</span> <span class="sc">~</span> LungCancer<span class="sc">|</span>Smoking <span class="sc">+</span> Bronchitis<span class="sc">|</span>Smoking)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.271</span></span></code></pre></div>
<p>It means that an arrow from Smoking to LungCancer
<strong>and</strong> an arrow from Smoking to Bronchitis appears in
27.073% of the sampled DAGs. This probability cannot be read from the
matrix above. Indeed, it is a structural statement.</p>
<p>If one wants to query positive and negative statements such as
<strong>What is the probability of the previous statement when there is
no arc from Smoking to Tuberculosis and no arc from Bronchitis to
XRay?</strong></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">query</span>(<span class="at">mcmcabn =</span> mcmc<span class="fl">.2</span>par.asia ,<span class="at">formula =</span> <span class="sc">~</span>LungCancer<span class="sc">|</span>Smoking <span class="sc">+</span> Bronchitis<span class="sc">|</span>Smoking <span class="sc">-</span> Tuberculosis<span class="sc">|</span>Smoking <span class="sc">-</span> XRay<span class="sc">|</span>Bronchitis)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.002</span></span></code></pre></div>
<p>So essentially zero!</p>
<div id="formula-statement-for-dag-specifications" class="section level3">
<h3>Formula statement for DAG specifications</h3>
<p>The <strong>formula</strong> statement has been designed to ease
querying over the MCMC samples. Hence, without explicitly writing an
adjacency matrix (which can be painful when the number of variables
increases). The <code>formula</code> argument can be provided using a
formula alike:</p>
<p><code>~ node1|parent1:parent2 + node2:node3|parent3</code>. The
formula statement has to start with <code>~</code>. In this example,
node1 has two parents (parent1 and parent2). node2 and node3 have the
same parent3. The parents’ names have to match those given in
<code>data.dist</code> exactly. <code>:</code> is the separator between
either children or parents, <code>|</code> separates children (left
side), and parents (right side), <code>+</code> separates terms,
<code>.</code> replaces all the variables in name. Then, the arrows go
from the left to the right side of the formula. Additionally, when one
wants to exclude an arc put <code>-</code> in front of that statement.
Then a formula like: <code>~ -node1|parent1</code> excludes all DAGs
that have an arc between parent1 and node1. Alternatively, one can query
using an adjacency matrix. This matrix should have only: 0,1 and -1. The
1 indicates the requested arcs, the -1 the excluded, and the 0 all other
entries that are not subject to constraints. The rows indicate the set
of parents of the index nodes. The order of rows and columns should be
the same as the ones used in the <code>mcmcabn()</code> function in the
<code>data.dist</code> argument. The matrix should not be named, but it
should be squared.</p>
</div>
<div id="technical-foundations" class="section level2">
<h2>Technical foundations</h2>
<p><em>Note: The terms: Bayesian networks, networks, structures, and
graphs are considered as synonyms.</em></p>
<p>This part aimed at describing the implemented methodology in
<code>mcmcabn</code>. The rationale for <em>mcmcabn</em> methodology is
that MCMC over DAGs allows the user to query the family of high scoring
DAGs and then draw a more general conclusion than using only one DAG.
The rationale for using structural algorithms for sampling the DAG space
and not the classical node ordering MCMC described by Friedman and
Koller (2003) is that it is biased. Additionally, it is not transparent
regarding the prior. One characteristic of the systems epidemiology
dataset is that data are scarce. Thus, in a Bayesian setting, the prior
play a significant role. Thus it is of high importance to be transparent
about our prior belief. Finally, the structural approach allows
user-defined a tunable prior, which is of great interest in an applied
perspective.</p>
<p>The three main problems addressed by this methodology are:</p>
<div id="selecting-the-most-probable-structure-based-on-a-cache-of-pre-computed-scores" class="section level3">
<h3>Selecting the most probable structure based on a cache of
pre-computed scores</h3>
<p>MCMC over DAGs produces estimates of high scoring structures. The
actual alternatives are the <code>mostProable()</code> (for exact
search) or <code>search.heuristic()</code> (for approximate search) R
functions in the <code>abn</code> R package, for example. The former
function performs an exact search, but it is limited to 25 nodes DAGs.
The latter performs approximate inference.</p>
</div>
<div id="controlling-for-overfitting" class="section level3">
<h3>Controlling for overfitting</h3>
<p>Classically, one wants to select the single most robust DAG, which
can then be used for prediction or inference. A major concern in
Bayesian network modeling is controlling overfitting. To this end, it is
advised to perform parametric or non-parametric bootstrapping in
generating samples from a chosen DAG structure or the data and then
determining which subset of the selected structure is supported by the
observed data. One can control for overfitting using
<code>mcmcabn</code> R package. Indeed, it returns the set of highly
supported structures with their individual support. Inspecting them
allows the user to make a general claim about individual arc
support.</p>
</div>
<div id="marginalizing-relationship-of-interest-over-nuisance-dependencies" class="section level3">
<h3>Marginalizing relationship of interest over nuisance
dependencies</h3>
<p>Sampling from the posterior distribution of structure could be
beneficial in an applied perspective to avoid reducing the richness of
Bayesian network modeling to only <strong>one</strong> structure.
Indeed, it allows the user to quantify the marginal impact of
relationships of interest by marginalizing out over structures or
nuisance dependencies, hence accounting for the uncertainty in the
structures through Bayesian model averaging. Structural MCMC seems an
elegant and natural way to estimate the <em>true</em> marginal impact,
so one can determine if it’s magnitude is big enough to consider as a
worthwhile intervention.</p>
</div>
</div>
<div id="posterior-distribution-of-the-structures" class="section level2">
<h2>Posterior distribution of the structures</h2>
<p>Form a mathematical perspective, one wants to sample over all
possible structures in moving from structures to structures according to
its support by the data. The posterior distribution of the structures is
given by:</p>
<p><span class="math display">\[p(G|D) = \frac{p(G, D)}{p(D)} =
\frac{p(D|G)p(G)}{z^*}\]</span></p>
<p>Where <span class="math inline">\(G\)</span> is a Bayesian network,
<span class="math inline">\(D\)</span> the data, and <span class="math inline">\(z^*\)</span> is a normalization factor. In a
score-based approach, the likelihood i.e., <span class="math inline">\(p(D|G)\)</span> are precisely the pre-computed
scores. In <code>mcmcabn</code> they have been pre-computed using
<code>abn</code> and stored in a cache of scores. Once one get an
estimate of the posterior distribution, one can compute the posterior
probability of any structural feature (<span class="math inline">\(f\)</span>) from an MCMC sample by</p>
<p><span class="math display">\[E[f|D] \approx \frac{1}{S}
\sum_{s=1}^{S}f(G^s), \text{ where } G^s \sim p(G|D)\]</span></p>
<p>where <span class="math inline">\(f\)</span> is any structural query
(<code>formula</code> statement in the <code>query()</code> function)
and <span class="math inline">\(S\)</span> is the set of visited
structures <span class="math inline">\(G\)</span>.</p>
<p>Classically, structural MCMC is done using the algorithm described by
Madigan and York (1995) and Giudici and Castelo (2003). It is called the
Monte Carlo Markov Chain Model Choice ((MC)<span class="math inline">\(^3\)</span>). It is an algorithm based on a single
edge move: deletion, addition, or reversal. This algorithm is known to
be slow in mixing and easily stuck in local maxima. Multiple updates
have been proposed. The idea is to perform a more drastic change in the
proposed DAG to cross low probability regions more efficiently.</p>
<p>Friedman and Koller (2003) proposed the order MCMC. This MCMC scheme
acts on the node order, improving a lot the convergence of the
algorithm. However, this algorithm is biased as a given DAG may belong
to a different order. A solution has been proposed by Kuipers and Moffa
(2017). It acts on the ordered partitions, which makes DAG having a
unique representation. This algorithm is implemented in the R package <a href="https://CRAN.R-project.org/package=BiDAG">BiDAG</a>. Goudie and
Mukherjee (2016) proposed a Gibbs sampling approach. Finaly, Grzegorczyk
and Husmeier (2008) and Su and Borsuk (2016) proposed two drastic MCMC
moves. They are implemented in this R package.</p>
<div id="algorithms" class="section level3">
<h3>Algorithms</h3>
<p>Two structurally, prior transparent, large scale moves have been
proposed: the new edge reversal move (REV) and the Markov blanket
resampling (MBR). The former advocates to make a reversal move in
resampling the parent set. The classical reversal move depends on the
global configuration of the parents and children and then fails to
propose MCMC jumps that produces valid but very different DAGs in a
unique move. It is known to be unbiased, but the assumption of
ergodicity does not necessarily hold. Then it has to be mixed with
(MC)<span class="math inline">\(^3\)</span> moves. In the MBR the same
idea is applied but to the entire Markov blanket of a randomly chosen
node.</p>
<p>We believe that having those three algorithms in a unique function
with user-adjustable relative frequencies leads to better results than
individual implementations. Those three algorithms work very
differently. The (MC)<span class="math inline">\(^3\)</span> is very
stable and samples efficiently the nearby region. The REV and MBR
potentially produce large scale MCMC jumps but differently and possibly
complementary.</p>
<p>The general method is the Metropolis Hasting algorithm. Essentially,
it is a sequential application of two steps:</p>
<ol style="list-style-type: decimal">
<li>a new DAG is proposed from some proposal distribution Q</li>
<li>the proposed DAG is accepted with some acceptance probability A</li>
</ol>
<p>The distribution Q has to be smart. The closer it is from the
posterior, the faster will the algorithm converges. To compute the
acceptance probability, one needs to compute the posterior probability
of each DAG. In this step, the prior on the index structure plays a
significant role.</p>
</div>
<div id="priors" class="section level3">
<h3>Priors</h3>
<p>Three priors are implemented in the <code>mcmcabn</code> R package.
The parameter <code>prior.choice</code> determines the prior used within
each node for a given choice of parent combination. In Koivisto and Sood
(2004) p.554, a form of prior called the Koivisto prior, is used, which
assumes that the prior probability for parent combinations comprising
the same number of parents are all equal.</p>
<p>Explicitly, the Koivisto prior is given by</p>
<p><span class="math display">\[p(G) = \frac{1}{z}\prod_{n=1}^N {N-1
\choose |G_n|}^{-1}\]</span> where <span class="math inline">\(N\)</span> is the total number of nodes and <span class="math inline">\(|G_n|\)</span> is the cardinality of the <span class="math inline">\(n\)</span>th node (i.e. the number of parents). As
we are in a MCMC setting and we will compute an Hasting ratio, the
normalizing constant <span class="math inline">\(z\)</span> will cancel
out.</p>
<p>Note that this prior favors parent combinations with either very low
or very high cardinalities, which may not be appropriate. This prior is
used when <code>prior.choice = 2</code>.</p>
<p>When <code>prior.choice = 1</code>, an uninformative prior is used
where parent combinations of all cardinalities are equally likely.</p>
<p>When <code>prior.choice = 3</code> a user-defined prior is used,
defined by <code>prior.dag</code>. It is given by an adjacency matrix
(squared and same size as number of nodes) where entries ranging from
zero to one give the user prior belief. An hyperparameter defining the
global user belief in the prior is given by <code>prior.lambda</code>.
In the vein of Werhli and Husmeier (2007) we defined the biological
prior knowledge matrix <span class="math inline">\(B\)</span> where the
rows are the parents set and the columns are the children, each entry
<span class="math inline">\(B_{ij} \in [0,1]\)</span> is such that:</p>
<ul>
<li><span class="math inline">\(B_{ij}\)</span> = 0.5, indicates no
prior knowledge about the presence or absence of an arc between nodes i
and j.</li>
<li><span class="math inline">\(B_{ij} \in [0,0.5[\)</span> indicates a
prior belief that there is no arc between node i and j. The belief gets
stronger as <span class="math inline">\(B_{ij}\)</span> gets closer to
0.</li>
<li><span class="math inline">\(B_{ij} \in ]0.5,1]\)</span> indicates a
prior belief that there is an arc between nodes i and j. The belief gets
stronger as <span class="math inline">\(B_{ij}\)</span> gets closer to
1.</li>
</ul>
<p>Such a matrix is still not a prior as we need to introduce a proper
normalization procedure. To do so, let us define the energy of a
structure as</p>
<p><span class="math display">\[E(G) = \sum_{i,j=1}^N |B_{i,j}
−G_{i,j}|\]</span></p>
<p>The energy <span class="math inline">\(E\)</span> is zero for a
perfect match between the prior knowledge <span class="math inline">\(B\)</span> and the actual network <span class="math inline">\(G\)</span>, while increasing values of <span class="math inline">\(E\)</span> indicates an increasing divergence
between <span class="math inline">\(B\)</span> and <span class="math inline">\(G\)</span>. Following, Imoto et al. (2003) we
define the prior belief on graph <span class="math inline">\(G\)</span>
by</p>
<p><span class="math display">\[p(G) = \frac{\exp({-\lambda
E(G)})}{z^*}\]</span> where <span class="math inline">\(z^*\)</span> is
a normalizing constant, and <span class="math inline">\(\lambda\)</span>
is a hyperparameter defined by <code>prior.lambda</code>. In an MCMC
setting the normalizing constant will canceled out in the Hasting
ratio.</p>
<p>In statistical physics, in a Gibbs distribution, the hyperparameter
<span class="math inline">\(\lambda\)</span> is the inverse of
temperature. It can be interpreted as a proxy indicating the strength of
the influence of the prior over the data. Thus the strength of the user
belief in the given prior. For <span class="math inline">\(\lambda
\rightarrow 0\)</span>, the prior distribution becomes flatter then
uninformative about the structure. Inversely, for <span class="math inline">\(\lambda \rightarrow \infty\)</span>, the prior
distribution becomes sharply peaked at the network with the lowest
energy.</p>
</div>
</div>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<ul>
<li>Kratzer, Gilles, et al. (2020). “Bayesian Networks modeling applied
to Feline Calicivirus infection among cats in Switzerland.” Frontiers in
Veterinary Science 7: 73.</li>
<li>Madigan, D. and York, J. (1995) “Bayesian graphical models for
discrete data”. International Statistical Review, 63:215–232.</li>
<li>Giudici, P. and Castelo, R. (2003). “Improving Markov Chain Monte
Carlo model search for data mining”. Machine Learning, 50:127–158.</li>
<li>Kratzer, G. and Furrer, R. (2019) “Is a single unique Bayesian
network enough to accurately represent your data?”. arXiv preprint
arXiv:1902.06641.</li>
<li>Friedman, N. and Koller, D. (2003). “Being Bayesian about network
structure. A Bayesian approach to structure discovery in Bayesian
networks.” Machine Learning, 50:95–125, 2003.</li>
<li>Grzegorczyk, M. and Husmeier, D. “Improving the structure MCMC
sampler for Bayesian networks by introducing a new edge reversal move”,
Machine Learning, vol. 71(2-3), pp. 265, 2008.</li>
<li>Su, C. and Borsuk, M. E. “Improving structure MCMC for Bayesian
networks through Markov blanket resampling”, The Journal of Machine
Learning Research, vol. 17(1), pp. 4042-4061, 2016.</li>
<li>Koivisto, M. V. (2004). Exact Structure Discovery in Bayesian
Networks, Journal of Machine Learning Research, vol 5, 549-573.</li>
<li>Werhli, A. V., and Husmeier, D. (2007). “Reconstructing gene
regulatory networks with Bayesian networks by combining expression data
with multiple sources of prior knowledge”. Statistical Applications in
Genetics and Molecular Biology, 6 (Article 15).</li>
<li>Imoto, S., Higuchi, T., Goto, T., Tashiro, K., Kuhara, S., and
Miyano, S. (2003). Using Bayesian networks for estimating gene networks
from microarrays and biological knowledge. In Proceedings of the
European Conference on Computational Biology.</li>
<li>Goudie, R. J., and Mukherjee, S. (2016). A Gibbs Sampler for
Learning DAGs. Journal of machine learning research: JMLR, 17(30),
1-39.</li>
<li>Kuipers, J. and Moffa, G. (2017). Partition MCMC for Inference on
Acyclic Digraphs, Journal of the American Statistical Association,
112:517, 282-299, DOI: 10.1080/01621459.2015.1133426</li>
<li>Scutari, M. (2010). Learning Bayesian Networks with the bnlearn R
Package. Journal of Statistical Software, 35(3), 1-22. </li>
</ul>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
